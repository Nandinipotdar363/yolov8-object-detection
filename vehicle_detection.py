# -*- coding: utf-8 -*-
"""vehicle_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1itNTnlviOvOtHlem3gUHuI5maMXIxRAb

**<h1 style="color: #9933ff; font-size: 32px; font-family: TimesNewRoman">Import Libraries</h1>**
"""

!pip install ultralytics

# ‚úÖ 1. Check GPU Availability
import torch
print("Torch CUDA Available:", torch.cuda.is_available())
print("Torch Device:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU")

# ‚úÖ 2. Install YOLOv8 and Required Packages
!pip install ultralytics torch torchvision torchaudio opencv-python matplotlib seaborn tqdm termcolor pandas -q
!pip install -q wandb  # Ensures W&B is installed

# ‚úÖ 3. Disable Weights & Biases (W&B)
import os
os.environ["WANDB_DISABLED"] = "true"

import os
import cv2
import glob
import yaml
import random
import pathlib
import torch
import numpy as np
import pandas as pd
from PIL import Image
import seaborn as sns
from tqdm import tqdm
import matplotlib.image as mpimg
from ultralytics import YOLO
import matplotlib.pyplot as plt
from termcolor import colored
from IPython.display import Image, Video
from IPython.display import Image, display

!wandb disabled
import warnings
warnings.filterwarnings('ignore')

# ‚úÖ 5. Load YOLOv8 Model
model = YOLO("yolov8n.pt")  # Loads the pre-trained YOLOv8 model

# 6. Run YOLO on a Sample Image
!wget -O sample.jpg https://ultralytics.com/images/zidane.jpg  # Download a test image
results = model("sample.jpg")  # Run YOLOv8 inference

# ‚úÖ 7. Display Results
# results.show()  # This line caused the error because results is a list
results[0].show()  # Access the first element of the list (the prediction) and call show()
# Changed the path to match the image name
# Assuming that results[0].show() would have saved the image as sample.jpg in the current working directory
plt.imshow(mpimg.imread("sample.jpg"))
plt.axis("off")
plt.show()

# Upload the Kaggle API credentials file
from google.colab import files
files.upload()  # Upload kaggle.json

# Install Kaggle API
!pip install kaggle

# Move the kaggle.json to the correct directory
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset
!kaggle datasets download -d alkanerturan/vehicledetection

!unzip -q vehicledetection.zip -d /content/vehicle_dataset

!ls /content/vehicle_dataset

!ls -R /content/vehicle_dataset/VehiclesDetectionDataset

import os
print(os.listdir("/content/"))  # List files in /content

# Organizing the dataset
import os
import shutil

"""Preparing Dataset"""

# Organizing the dataset
import os
import shutil

"""**Verify dataset.yaml Content**

**Verify the Updated dataset.yaml**

Check Your Dataset **Classes**
"""



"""**<p style="color: #5c0099; font-size: 20px; font-family: TimesNewRoman">( Display random images from data )</p>**

**Check If the Dataset Exists**
"""

import os

dataset_path = "/content/vehicle_dataset"
if os.path.exists(dataset_path):
    print("‚úÖ Dataset folder exists!")
    print("üìÇ Contents of vehicle_dataset:", os.listdir(dataset_path))
else:
    print("‚ùå ERROR: Dataset folder not found! Check if it was extracted correctly.")

"""**Check the Correct Image Path**"""

import os

# Check contents of the VehiclesDetectionDataset folder
dataset_main_path = "/content/vehicle_dataset/VehiclesDetectionDataset"
if os.path.exists(dataset_main_path):
    print("‚úÖ VehiclesDetectionDataset exists!")
    print("üìÇ Contents:", os.listdir(dataset_main_path))
else:
    print("‚ùå ERROR: VehiclesDetectionDataset not found!")

"""**corrected Paths for Your Dataset**"""

train_path = "/content/vehicle_dataset/VehiclesDetectionDataset/train"
val_path = "/content/vehicle_dataset/VehiclesDetectionDataset/valid"
test_path = "/content/vehicle_dataset/VehiclesDetectionDataset/test"
yaml_path = "/content/vehicle_dataset/VehiclesDetectionDataset/dataset.yaml"

"""Verify Train Image **Files**"""

import os
from PIL import Image

# ‚úÖ Define the train images folder path
train_images_path = "/content/vehicle_dataset/VehiclesDetectionDataset/train/images"

# ‚úÖ Check if the directory exists
if not os.path.exists(train_images_path):
    print(f"‚ùå ERROR: Train image directory not found: {train_images_path}")
else:
    print(f"‚úÖ Train image directory found: {train_images_path}")

    # ‚úÖ Get all image files in the folder
    image_files = [f for f in os.listdir(train_images_path) if f.endswith(('.jpg', '.png', '.jpeg'))]

    # ‚úÖ Ensure we have images
    if len(image_files) == 0:
        print("‚ùå ERROR: No images found in the train directory!")
    else:
        print(f"‚úÖ Found {len(image_files)} train images.")

        # ‚úÖ Verify images by opening a few to check for corruption
        corrupted_files = []
        for image_file in image_files[:20]:  # Check the first 20 images
            image_path = os.path.join(train_images_path, image_file)
            try:
                img = Image.open(image_path)
                img.verify()  # Verify if image is valid
            except (IOError, SyntaxError) as e:
                corrupted_files.append(image_file)

        # ‚úÖ Print summary
        if corrupted_files:
            print(f"‚ùå WARNING: {len(corrupted_files)} corrupted images found!")
            print("Corrupted files:", corrupted_files)
        else:
            print("‚úÖ All tested images are valid!")

"""Display Random Images from the Correct **Path**"""

import os
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# ‚úÖ Define the train images folder path
train_images_path = "/content/vehicle_dataset/VehiclesDetectionDataset/train/images"

# ‚úÖ Check if the directory exists
if not os.path.exists(train_images_path):
    print(f"‚ùå ERROR: Train image directory not found: {train_images_path}")
else:
    print(f"‚úÖ Train image directory found: {train_images_path}")

    # ‚úÖ List all image files
    image_files = [f for f in os.listdir(train_images_path) if f.endswith(('.jpg', '.png', '.jpeg'))]

    # ‚úÖ Ensure we have images
    if len(image_files) == 0:
        print("‚ùå ERROR: No images found in the train directory!")
    else:
        print(f"‚úÖ Found {len(image_files)} train images.")

        # ‚úÖ Select 16 random images for display
        random_images = random.sample(image_files, min(16, len(image_files)))

        # ‚úÖ Display images in a 4x4 grid
        fig, axes = plt.subplots(4, 4, figsize=(12, 12))
        for i, ax in enumerate(axes.flat):
            img_path = os.path.join(train_images_path, random_images[i])
            img = mpimg.imread(img_path)
            ax.imshow(img)
            ax.axis("off")  # Hide axes
            ax.set_title(f"Image {i+1}")

        plt.tight_layout()
        plt.show()

"""**<p style="color: #5c0099; font-size: 20px; font-family: TimesNewRoman">( Try pre-trained yolov8 on random images )</p>**

"""

import os
import random
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from ultralytics import YOLO

# ‚úÖ Define dataset paths
train_path = "/content/vehicle_dataset/VehiclesDetectionDataset/train/images"
val_path = "/content/vehicle_dataset/VehiclesDetectionDataset/valid/images"
test_path = "/content/vehicle_dataset/VehiclesDetectionDataset/test/images"
yaml_path = "/content/vehicle_dataset/VehiclesDetectionDataset/dataset.yaml"

# ‚úÖ Choose which dataset to use for visualization
images_folder = test_path  # Change to train_path or val_path if needed

# ‚úÖ List and filter image files
image_files = [f for f in os.listdir(images_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]

# ‚úÖ Ensure we have at least 20 images
if len(image_files) < 20:
    print(f"‚ùå ERROR: Not enough images in {images_folder}!")
else:
    print(f"‚úÖ Found {len(image_files)} images in {images_folder}.")

    # ‚úÖ Select 20 random images
    random_images = random.sample(image_files, 20)

    # ‚úÖ Load the YOLOv8 model
    model = YOLO("yolov8n.pt")

    # ‚úÖ Process and display each selected image
    for image_file in random_images:
        image_path = os.path.join(images_folder, image_file)

        # ‚úÖ Perform object detection
        results = model.predict(source=image_path, imgsz=416)

        # ‚úÖ Load the original image
        original_image = Image.open(image_path).convert("RGB")

        # ‚úÖ Process predictions
        for result in results:
            # ‚úÖ Convert result to image format
            plot = result.plot()
            predicted_image = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)

            # ‚úÖ Convert to PIL image
            predicted_image = Image.fromarray(predicted_image)

            # ‚úÖ Combine original and predicted images side by side
            combined_width = original_image.width + predicted_image.width
            combined_height = max(original_image.height, predicted_image.height)
            combined_image = Image.new("RGB", (combined_width, combined_height))
            combined_image.paste(original_image, (0, 0))
            combined_image.paste(predicted_image, (original_image.width, 0))

            # ‚úÖ Display the combined image using Matplotlib
            plt.figure(figsize=(12, 6))
            plt.imshow(combined_image)
            plt.axis("off")
            plt.title(f"YOLOv8 Detection: {image_file}")
            plt.show()

"""Install and Import **YOLOv8**"""

!pip install ultralytics -q  # Install YOLOv8 library

from ultralytics import YOLO
import cv2
import torch
import os
import random
import matplotlib.pyplot as plt

model = YOLO("yolov8n.pt")  # Using YOLOv8 nano (smallest version)

"""**<h1 style="color: #9933ff; font-size: 32px; font-family: TimesNewRoman">Training model</h1>**

**Install YOLOv8 (Ultralytics)**
"""

!pip install ultralytics -q  # Install YOLOv8 library

"""**Import required libraries:**"""

from ultralytics import YOLO
import torch
import os

"""**Verify GPU Availability**"""

print("CUDA Available: ", torch.cuda.is_available())
print("GPU Name: ", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU will be used")

"""**Define Paths**"""

# Define path to the dataset.yaml file
dataset_yaml = "/content/vehicle_dataset/VehiclesDetectionDataset/dataset.yaml"

"""**Train the YOLOv8 Model**"""

# Load YOLOv8 model (Nano version)
model = YOLO("yolov8n.yaml")  # Load YOLOv8 model for training

# Train the model
model.train(data=dataset_yaml, epochs=50, imgsz=640, batch=16, device=0)

"""**Check Training Results**"""

from IPython.display import display
from PIL import Image

# Display training results image (shows loss & mAP charts)
display(Image.open("/content/runs/detect/train/results.png"))

"""**Locate Your Trained Model**"""

import locale
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding

!ls /content/runs/detect/train/weights/

"""**Test Your Model on an Image**

**<h1 style="color: #9933ff; font-size: 32px; font-family: TimesNewRoman">Training Results</h1>**
"""

from IPython.display import Image, display

# Correct path to confusion matrix in Google Colab
confusion_matrix_path = "/content/runs/detect/train/confusion_matrix_normalized.png"

# Display the confusion matrix
display(Image(filename=confusion_matrix_path))

"""**Displays YOLOv8 training results loss, mAP, recall, precision charts**"""

from IPython.display import Image, display

# Correct path for training results in Google Colab
results_path = "/content/runs/detect/train/results.png"

# Display the training results image
display(Image(filename=results_path))

"""**Displays the F1-Score curve from YOLOv8 training.**"""

from IPython.display import Image, display

# Correct path for F1 curve in Google Colab
F1_path = "/content/runs/detect/train/F1_curve.png"

# Display the F1 curve image
display(Image(filename=F1_path))

"""**Loads YOLOv8 training results CSV in Google Colab.**"""

import pandas as pd

# Correct path for training results CSV in Google Colab
csv_path = "/content/runs/detect/train/results.csv"

# Load the CSV file
training_results = pd.read_csv(csv_path)

# Print the column names
print(training_results.columns)

"""**Loads results correctly from the results.csv file.**"""

# Plot metrics during training

import matplotlib.pyplot as plt
import pandas as pd

# Load training results from YOLOv8 training logs
results_csv_path = "/content/runs/detect/train/results.csv"

# Check if the file exists before proceeding
if not os.path.exists(results_csv_path):
    print(f"‚ùå ERROR: Training results file not found at {results_csv_path}")
else:
    # Read CSV file into a Pandas DataFrame
    training_results = pd.read_csv(results_csv_path)

    # Display the first few rows to check column names
    print("‚úÖ Training results loaded successfully!")
    print(training_results.head())

    # Check column names before plotting
    expected_columns = ['epoch', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']
    missing_columns = [col for col in expected_columns if col not in training_results.columns]

    if missing_columns:
        print(f"‚ùå ERROR: Missing columns in training results: {missing_columns}")
    else:
        # Plot metrics during training
        plt.figure(figsize=(7, 5))  # A smaller plot
        plt.plot(training_results['epoch'], training_results['metrics/precision(B)'], label='Precision', marker='o')
        plt.plot(training_results['epoch'], training_results['metrics/recall(B)'], label='Recall', marker='s')
        plt.plot(training_results['epoch'], training_results['metrics/mAP50(B)'], label='mAP@50', marker='^')
        plt.plot(training_results['epoch'], training_results['metrics/mAP50-95(B)'], label='mAP@50-95', marker='d')

        plt.xlabel('Epoch')
        plt.ylabel('Metrics')
        plt.title('Model Performance Metrics During Training')
        plt.legend()
        plt.grid()
        plt.show()

"""**<h1 style="color: #9933ff; font-size: 32px; font-family: TimesNewRoman">Evaluating trained model perforance on the test set</h1>**"""

from ultralytics import YOLO

# Correct model path in Google Colab
best_model_path = "/content/runs/detect/train/weights/best.pt"

# Load trained YOLOv8 model
best_model = YOLO(best_model_path)

# Evaluate the model on the test set
metrics = best_model.val(split='test')

# Display the evaluation metrics
print(metrics)

"""**<p style="color: #5c0099; font-size: 20px; font-family: TimesNewRoman">Validating the model's predictions on unseen data</p>**


"""

!pip install ultralytics

import os
import random
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from ultralytics import YOLO

# ‚úÖ Define test dataset path
test_path = "/content/vehicle_dataset/VehiclesDetectionDataset/test/images"

# ‚úÖ Check if test directory exists
if not os.path.exists(test_path):
    print(f"‚ùå ERROR: Test image directory not found: {test_path}")
else:
    print(f"‚úÖ Test image directory found: {test_path}")

    # ‚úÖ List all test images
    test_images = [f for f in os.listdir(test_path) if f.endswith(('.jpg', '.png', '.jpeg'))]

    # ‚úÖ Ensure images exist
    if len(test_images) == 0:
        print("‚ùå ERROR: No images found in test directory!")
    else:
        print(f"‚úÖ Found {len(test_images)} test images.")

        # ‚úÖ Load trained YOLOv8 model
        best_model_path = "/content/runs/detect/train/weights/best.pt"

        if not os.path.exists(best_model_path):
            print(f"‚ùå ERROR: Trained model not found at {best_model_path}")
        else:
            print(f"‚úÖ Using trained model: {best_model_path}")

            model = YOLO(best_model_path)

            # ‚úÖ Select random images for validation
            random_images = random.sample(test_images, min(10, len(test_images)))  # Pick up to 10 images

            # ‚úÖ Display predictions
            for image_file in random_images:
                image_path = os.path.join(test_path, image_file)

                # Load image
                image = Image.open(image_path).convert("RGB")
                image_np = np.array(image)

                # Perform inference (predictions)
                results = model.predict(image_np, imgsz=640, conf=0.5, iou=0.7)

                # Get the annotated image
                plot = results[0].plot()
                annotated_image = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)

                # Display original and predicted images
                fig, axes = plt.subplots(1, 2, figsize=(12, 6))
                axes[0].imshow(image)
                axes[0].set_title("Original Image")
                axes[0].axis("off")

                axes[1].imshow(annotated_image)
                axes[1].set_title("YOLOv8 Detection")
                axes[1].axis("off")

                plt.tight_layout()
                plt.show()

import os
import random
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from ultralytics import YOLO

# ‚úÖ Define test dataset path
test_path = "/content/vehicle_dataset/VehiclesDetectionDataset/test/images"

# ‚úÖ Ensure test directory exists
if not os.path.exists(test_path):
    print(f"‚ùå ERROR: Test image directory not found: {test_path}")
else:
    print(f"‚úÖ Test image directory found: {test_path}")

    # ‚úÖ List test images
    image_files = [os.path.join(test_path, file) for file in os.listdir(test_path) if file.endswith(('.jpg', '.png', '.jpeg'))]

    # ‚úÖ Ensure images exist
    if len(image_files) == 0:
        print("‚ùå ERROR: No images found in test directory!")
    else:
        print(f"‚úÖ Found {len(image_files)} test images.")

        # ‚úÖ Load trained YOLOv8 model
        best_model_path = "/content/runs/detect/train/weights/best.pt"

        if not os.path.exists(best_model_path):
            print(f"‚ùå ERROR: Trained model not found at {best_model_path}")
        else:
            print(f"‚úÖ Using trained model: {best_model_path}")

            best_model = YOLO(best_model_path)

            # ‚úÖ Select random images for testing
            random_images = random.sample(image_files, min(10, len(image_files)))

            # ‚úÖ Set up a directory for saving results
            save_dir = "/content/yolo_results"
            os.makedirs(save_dir, exist_ok=True)
            print(f"‚úÖ Results will be saved in: {save_dir}")

            # ‚úÖ Run inference and display results
            for image_path in random_images:
                # Load the image
                image = Image.open(image_path).convert("RGB")
                image_np = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

                # Perform object detection
                results = best_model.predict([image_np], save_dir=save_dir, imgsz=416, conf=0.5, iou=0.7)

                # Get the annotated image
                plot = results[0].plot()
                annotated_image = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)

                # Display original and detected images
                fig, axes = plt.subplots(1, 2, figsize=(12, 6))
                axes[0].imshow(image)
                axes[0].set_title("Original Image")
                axes[0].axis("off")

                axes[1].imshow(annotated_image)
                axes[1].set_title("YOLOv8 Detection")
                axes[1].axis("off")

                plt.tight_layout()
                plt.show()

import os
video_dir = "/content/vehicle_dataset/"
print(os.listdir(video_dir))  # Check available files and folders

import os

video_dir = "/content/vehicle_dataset/TestVideo"
print(os.listdir(video_dir))  # List files in TestVideo folder

import os
import cv2
from ultralytics import YOLO

# ‚úÖ Define test video path
video_path = "/content/vehicle_dataset/TestVideo/TrafficPolice.mp4"
output_video_path = "/content/yolo_results/detected_trafficpolice.mp4"

# ‚úÖ Check if the video exists
if not os.path.exists(video_path):
    print(f"‚ùå ERROR: Test video not found at {video_path}")
else:
    print(f"‚úÖ Test video found: {video_path}")

    # ‚úÖ Load trained YOLOv8 model
    best_model_path = "/content/runs/detect/train/weights/best.pt"

    if not os.path.exists(best_model_path):
        print(f"‚ùå ERROR: Trained model not found at {best_model_path}")
    else:
        print(f"‚úÖ Using trained model: {best_model_path}")
        model = YOLO(best_model_path)

        # ‚úÖ Perform object detection on the video
        results = model.predict(source=video_path, save=True, save_txt=True, save_conf=True, conf=0.5, iou=0.7)

        # ‚úÖ Save processed video
        if os.path.exists(output_video_path):
            print(f"‚úÖ Processed video saved at: {output_video_path}")
        else:
            print("‚ùå ERROR: Processed video not saved correctly.")

import os
import cv2
import torch
from ultralytics import YOLO

# ‚úÖ Define video paths
video_path = "/content/vehicle_dataset/TestVideo/TrafficPolice.mp4"
output_video_path = "/content/yolo_results/detected_TrafficPolice.mp4"

# ‚úÖ Check if video file exists
if not os.path.exists(video_path):
    print(f"‚ùå ERROR: Test video not found at {video_path}")
else:
    print(f"‚úÖ Test video found: {video_path}")

    # ‚úÖ Load YOLOv8 trained model
    best_model_path = "/content/runs/detect/train/weights/best.pt"

    if not os.path.exists(best_model_path):
        print(f"‚ùå ERROR: Trained model not found at {best_model_path}")
    else:
        print(f"‚úÖ Using trained model: {best_model_path}")
        model = YOLO(best_model_path)

        # ‚úÖ Open video file
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("‚ùå ERROR: Failed to open the video file.")
            exit()

        # ‚úÖ Get video properties
        frame_width = int(cap.get(3))
        frame_height = int(cap.get(4))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"üìΩÔ∏è Video Info: {frame_width}x{frame_height}, {fps} FPS, {total_frames} Frames")

        # ‚úÖ Define video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))

        frame_count = 0  # Track processed frames

        while True:
            ret, frame = cap.read()
            if not ret:
                break  # End of video

            # ‚úÖ Run YOLOv8 inference on the frame
            results = model.predict(frame, conf=0.3, iou=0.5, imgsz=640)

            # ‚úÖ Get annotated frame
            annotated_frame = results[0].plot()

            # ‚úÖ Write frame to output video
            out.write(annotated_frame)
            frame_count

from ultralytics import YOLO

model = YOLO("/content/runs/detect/train/weights/best.pt")  # Update the path if needed

"""**Convert the model to ONNX format:**


"""

model.export(format="onnx")

"""**Test ONNX model inference using ONNX Runtime:**"""

import onnxruntime as ort

session = ort.InferenceSession("/content/runs/detect/train/weights/best.onnx")
print("ONNX model loaded successfully!")

"""**Download ONNX**"""

from google.colab import files
files.download("/content/runs/detect/train/weights/best.onnx")